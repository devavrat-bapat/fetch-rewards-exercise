{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1>FETCH REWARDS EXERCISE</h1><br>\n",
    "Job position - Data Engineer<br><br>\n",
    "\n",
    "Title - Finding similarity between two texts<br>\n",
    "Applicant/Author - <b>Devavrat Bapat</b><br>\n",
    "Email id - <b>bapat.dev@gmail.com</b><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2>Pre-processing the data</h2><br>\n",
    "Steps involved -<br><br>\n",
    "\n",
    "2.1 convert text into lower case words<br>\n",
    "2.2 word stemming (not implemented)<br>\n",
    "2.3 remove punctuation symbols (except apostrphe)<br>\n",
    "2.4 remove stopwords<br>\n",
    "2.5 convert text into a list of words<br>\n",
    "2.6 remove stop words post lemmatisation<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2.1\n",
    "\n",
    "# Turn everything small caps\n",
    "\n",
    "def lowerCaseWords(text):\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2.2\n",
    "\n",
    "# Convert words into their root words\n",
    "\n",
    "def wordStemming(text):\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2.3\n",
    "\n",
    "# Remove punctuation symbols from text\n",
    "\n",
    "def removeSymbols(text):\n",
    "    punctuationSymbols = ['.', ',', '?', '!', ';', ':', '-', '{', '}', '[', ']', '(', ')', '\"', '*', '/', '&', '^', '%','$', '#', '@', '+']\n",
    "    for symbol in punctuationSymbols:\n",
    "        text = text.replace('' + symbol, '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2.4\n",
    "\n",
    "# Remove stop words from the text\n",
    "\n",
    "def removeStopWords(text):\n",
    "\n",
    "    stopWords = [\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"aren't\",\n",
    "                 \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"can't\", \"cannot\",\n",
    "                 \"could\", \"couldn't\", \"did\",\"didn't\", \"do\", \"does\", \"doesn't\", \"doing\", \"don't\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\",\n",
    "                 \"further\", \"had\", \"hadn't\",\"has\", \"hasn't\", \"have\", \"haven't\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\",\n",
    "                 \"hers\", \"herself\", \"him\",\"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"isn't\",\n",
    "                 \"it\",\"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"mustn't\", \"my\", \"myself\", \"no\", \"nor\", \"not\",\n",
    "                 \"of\", \"off\",\"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\t\", \"ourselves\", \"out\", \"over\", \"own\",\n",
    "                 \"same\", \"shan't\", \"she\",\"she'd\", \"she'll\", \"she's\", \"should\", \"shouldn't\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\",\n",
    "                 \"the\", \"their\", \"theirs\", \"them\",\"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\",\n",
    "                 \"this\", \"those\", \"through\", \"to\", \"too\",\"under\", \"until\", \"up\", \"very\", \"was\", \"wasn't\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\",\n",
    "                 \"weren't\", \"what\", \"what's\",\"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\",\n",
    "                 \"won't\", \"would\", \"wouldn't\",\"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\"]\n",
    "\n",
    "    for stopWord in stopWords:\n",
    "        text = text.replace(' ' + stopWord + ' ', ' ')\n",
    "\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2.5\n",
    "\n",
    "# Turn text into a list of multiple strings of individual words | Tokenization\n",
    "def splitText(text):\n",
    "    text = text.split()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2.6\n",
    "\n",
    "# This step is being repeated to remove any stop words occuring due to punctuation symbols or at\n",
    "#  the start or end of a sentence.\n",
    "\n",
    "def removeStopWordsPostSplit(text):\n",
    "\n",
    "    stopWords = [\"a\",\"about\",\"above\",\"after\",\"again\",\"against\",\"all\",\"am\",\"an\",\"and\",\"any\",\"are\",\"aren't\",\"as\",\"at\",\n",
    "                \"be\",\"because\",\"been\",\"before\",\"being\",\"below\",\"between\",\"both\",\"but\",\"by\",\"can't\",\"cannot\",\"could\",\"couldn't\",\"did\",\n",
    "                \"didn't\",\"do\",\"does\",\"doesn't\",\"doing\",\"don't\",\"down\",\"during\",\"each\",\"few\",\"for\",\"from\",\"further\",\"had\",\"hadn't\",\n",
    "                \"has\",\"hasn't\",\"have\",\"haven't\",\"having\",\"he\",\"he'd\",\"he'll\",\"he's\",\"her\",\"here\",\"here's\",\"hers\",\"herself\",\"him\",\n",
    "                \"himself\",\"his\",\"how\",\"how's\",\"i\",\"i'd\",\"i'll\",\"i'm\",\"i've\",\"if\",\"in\",\"into\",\"is\",\"isn't\",\"it\",\n",
    "                \"it's\",\"its\",\"itself\",\"let's\",\"me\",\"more\",\"most\",\"mustn't\",\"my\",\"myself\",\"no\",\"nor\",\"not\",\"of\",\"off\",\n",
    "                \"on\",\"once\",\"only\",\"or\",\"other\",\"ought\",\"our\",\"ours\t\",\"ourselves\",\"out\",\"over\",\"own\",\"same\",\"shan't\",\"she\",\n",
    "                \"she'd\",\"she'll\",\"she's\",\"should\",\"shouldn't\",\"so\",\"some\",\"such\",\"than\",\"that\",\"that's\",\"the\",\"their\",\"theirs\",\"them\",\n",
    "                \"themselves\",\"then\",\"there\",\"there's\",\"these\",\"they\",\"they'd\",\"they'll\",\"they're\",\"they've\",\"this\",\"those\",\"through\",\"to\",\"too\",\n",
    "                \"under\",\"until\",\"up\",\"very\",\"was\",\"wasn't\",\"we\",\"we'd\",\"we'll\",\"we're\",\"we've\",\"were\",\"weren't\",\"what\",\"what's\",\n",
    "                \"when\",\"when's\",\"where\",\"where's\",\"which\",\"while\",\"who\",\"who's\",\"whom\",\"why\",\"why's\",\"with\",\"won't\",\"would\",\"wouldn't\",\n",
    "                \"you\",\"you'd\",\"you'll\",\"you're\",\"you've\",\"your\",\"yours\",\"yourself\",\"yourselves\"]\n",
    "\n",
    "\n",
    "    for stopWord in stopWords:\n",
    "        if stopWord in text:\n",
    "            text.remove(''+stopWord)\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating log\n",
    "def lg(x):\n",
    "    n = 1000.0\n",
    "    return n * ((x ** (1/n)) - 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate document frequency, Term frequency, Inverse document frequency and  common words\n",
    "\n",
    "def dftf(text1_prep, text2_prep):\n",
    "\n",
    "    All_DF = {}\n",
    "    text1_TF = {}\n",
    "    text2_TF = {}\n",
    "    commonWords = {}\n",
    "    idf = {}\n",
    "    tfidf1 = {}\n",
    "    tfidf2 = {}\n",
    "\n",
    "    All_DF = {key: 0 for key in text1_prep + text2_prep}\n",
    "    text1_TF = {key: 0 for key in text1_prep + text2_prep}\n",
    "    text2_TF = {key: 0 for key in text1_prep + text2_prep}\n",
    "    commonWords = {key: 0 for key in text1_prep + text2_prep}\n",
    "    idf = {key: 0 for key in text1_prep + text2_prep}\n",
    "    tfidf1 = {key: 0 for key in text1_prep + text2_prep}\n",
    "    tfidf2 = {key: 0 for key in text1_prep + text2_prep}\n",
    "\n",
    "    for word in text1_prep:\n",
    "        text1_TF[word] = text1_TF[word] + 1\n",
    "        All_DF[word] = All_DF[word] + 1\n",
    "        commonWords[word] = 1\n",
    "\n",
    "    for word in text2_prep:\n",
    "        text2_TF[word] = text2_TF[word] + 1\n",
    "        All_DF[word] = All_DF[word] + 1\n",
    "        if commonWords[word] == 1:\n",
    "            commonWords[word] = 2\n",
    "        else:\n",
    "            commonWords[word] = 1\n",
    "\n",
    "    # Total words in each text\n",
    "\n",
    "    text1_totalWords = sum(text1_TF.values(), 0.0)\n",
    "    text2_totalWords = sum(text2_TF.values(), 0.0)\n",
    "\n",
    "    for k, v in text1_TF.items():\n",
    "        text1_TF[k] = text1_TF[k] / text1_totalWords\n",
    "\n",
    "    for k, v in text2_TF.items():\n",
    "        text2_TF[k] = text2_TF[k] / text2_totalWords\n",
    "\n",
    "    # Find IDF\n",
    "    for k, v in idf.items():\n",
    "        idf[k] = lg(1 + 2 / commonWords[k])\n",
    "\n",
    "    # Find tf.idf\n",
    "\n",
    "    for k, v in tfidf1.items():\n",
    "        tfidf1[k] = text1_TF[k] * idf[k]\n",
    "\n",
    "    for k, v in tfidf2.items():\n",
    "        tfidf2[k] = text2_TF[k] * idf[k]\n",
    "\n",
    "\n",
    "    return All_DF, text1_TF, text2_TF, text1_totalWords, text2_totalWords, commonWords, idf, tfidf1, tfidf2\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosineSimilarity(tfidf1, tfidf2):\n",
    "    total = 0\n",
    "\n",
    "    for k, v in tfidf1.items():\n",
    "        total = total + (tfidf1[k] * tfidf2[k])\n",
    "\n",
    "    sqr1 = 0\n",
    "    sqr2 = 0\n",
    "\n",
    "    tfidf1sqr = {}\n",
    "    tfidf2sqr = {}\n",
    "\n",
    "    for k, v in tfidf1.items():\n",
    "        tfidf1sqr[k] = tfidf1[k] ** 2\n",
    "\n",
    "    for k, v in tfidf2.items():\n",
    "        tfidf2sqr[k] = tfidf2[k] ** 2\n",
    "\n",
    "    norm_a = (sum(tfidf1sqr.values()) ** 0.5)\n",
    "    norm_b = (sum(tfidf2sqr.values()) ** 0.5)\n",
    "\n",
    "\n",
    "    score = total / (norm_a * norm_b)\n",
    "    print('The similarity score =',round(score,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    print('Inside preprocess')\n",
    "\n",
    "    text = lowerCaseWords(text)\n",
    "    text = wordStemming(text)\n",
    "    text = removeSymbols(text)\n",
    "    text = removeStopWords(text)\n",
    "    text = splitText(text)\n",
    "    text = removeStopWordsPostSplit(text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the program -\n",
    "\n",
    "\n",
    "#1) Set the texts you would like to compare\n",
    "\n",
    "Text1 = \"The easiest way to earn points with Fetch Rewards is to just shop for the products you already love. If you have any participating brands on your receipt, you'll get points based on the cost of the products. You don't need to clip any coupons or scan individual barcodes. Just scan each grocery receipt after you shop and we'll find the savings for you.\"\n",
    "\n",
    "Text2 = \"The easiest way to earn points with Fetch Rewards is to just shop for the items you already buy. If you have any eligible brands on your receipt, you will get points based on the total cost of the products. You do not need to cut out any coupons or scan individual UPCs. Just scan your receipt after you check out and we will find the savings for you.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside preprocess\n",
      "Inside preprocess\n"
     ]
    }
   ],
   "source": [
    "# 2) Execute preprocessing\n",
    "\n",
    "Text1_preprocessed = preprocess(Text1) \n",
    "Text2_preprocessed = preprocess(Text2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Execute TF.IDF calculation\n",
    "\n",
    "All_DF, text1_TF, text2_TF, text1_totalWords, text2_totalWords, commonWords, idf, tfidf1, tfidf2 = dftf(Text1_preprocessed, Text2_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The similarity score = 0.77\n"
     ]
    }
   ],
   "source": [
    "# 4) Execute cosine similarity and get the final score\n",
    "\n",
    "cosineSimilarity(tfidf1, tfidf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
